üéØ ***Objectif du repo***

Ce d√©p√¥t rassemble deux Travaux Pratiques (TP) complets ‚Äî chacun avec √©nonc√© et solution ‚Äî couvrant deux domaines cl√©s du machine learning :

1. NLP :

D√©sambigu√Øsation nom vs verbe (jeu de donn√©es noun-verb de Google Research)

Part-of-Speech Tagging (POS) sur donn√©es CoNLL (via pyconll)

Mod√®les LSTM/GRU et Transformers, m√©triques de s√©quence, pr√©paration DataLoader, entra√Ænement et analyse d‚Äôerreurs.

2. S√©ries temporelles (Time Series) :

R√©gression de la concentration de benz√®ne (jeu Benzene Concentration ‚Äì Zenodo)

Chargement/structuration avec aeon, features temporelles, normalisation, s√©paration temporelle stricte, entra√Ænement PyTorch Lightning et MSE/RMSE.

üìÇ ***Contenu***

**TP_3_1_√©nonc√©.ipynb** ‚Äî Pr√©diction de la concentration en benz√®ne (√©nonc√©)
Formulation du probl√®me, p√©rim√®tre des features, consignes d‚ÄôEDA, pr√©paration des jeux temporels (train/val/test), objectifs de m√©triques (MSE/RMSE).

**TP_3_1_ALLAKONON_VODOUMBO_solution.ipynb** ‚Äî Pr√©diction de la concentration en benz√®ne (solution)
Pipeline complet : ingestion avec aeon, features et normalisation, DataLoader, mod√®le PyTorch (r√©gression), entra√Ænement Lightning, suivi des pertes, visualisations et interpr√©tation des r√©sultats.

**TP_3_2_√©nonc√©.ipynb** ‚Äî NLP : d√©sambigu√Øsation nom/verbe & POS tagging (√©nonc√©)
T√¢ches s√©quentielles, pr√©paration des donn√©es CoNLL (pyconll), d√©finition des architectures (RNN/GRU/LSTM/Transformer), m√©triques s√©quence (accuracy/f1/recall selon la partie), et attentes d‚Äôanalyse d‚Äôerreurs.

**TP_3_2_solution.ipynb** ‚Äî NLP : d√©sambigu√Øsation nom/verbe & POS tagging (solution)
Impl√©mentations LSTM/GRU et Transformer : tokenisation, embeddings, masquage, DataLoader s√©quentiel, boucle d‚Äôentra√Ænement Lightning, torchmetrics pour le suivi, matrices de confusion/exemples mal class√©s, commentaires sur les compromis biais/variance.

üß∞ ***Stack & biblioth√®ques***

- Python 3 (Jupyter Notebooks)

- PyTorch & PyTorch Lightning (boucles d‚Äôentra√Ænement propres et reproductibles)

- torchmetrics, torchinfo (m√©triques et r√©sum√© de mod√®le)

- aeon (s√©ries temporelles : chargement/transformations)

- pyconll (parsing CoNLL pour POS)

- pandas, numpy, matplotlib.

üìä ***R√©sultats & insights***

- Benz√®ne : les variables temporelles et la structure d‚Äôagr√©gation am√©liorent significativement la RMSE vs baseline na√Øve; les diagnostics montrent l‚Äôimportance de la saisonnalit√© et de la variabilit√© intra-jour/semaine.

- NLP : le Transformer capture mieux les d√©pendances longues que les RNN classiques sur le POS tagging; l‚Äôanalyse d‚Äôerreurs met en √©vidence les ambigu√Øt√©s lexicales r√©currentes (homographes nom/verbe).